---
id: 'de-intro-4'
title: 'CH4 - 빅데이터의 축적'
---

## 벌크 형과 스트리밍 형의 데이터 수집

데이터를 전송하는 데는 벌크 형과 스트리밍 형, 두 종류의 도구가 사용된다. 

### 객체 스토리지와 데이터 수집

빅데이터는 대부분 확장성이 높은 **분산 스토리지**에 저장된다. 그리고 일반적으로 **오브젝트 스토리지(객체 스토리지)**를 활용한다. 대표적으로 Hadoop의 HDFS나 Amazon의 Amazon S3가 유명하다.

![Untitled](https://github.com/wookiist/til.wookiist.dev/blob/documentation/static/img/Data_Engineering/Introduction/object_storage.png?raw=true)

오브젝트 스토리지는 여러 노드를 사용해 파일을 여러 디스크에 복사해둠으로써 데이터 중복화와 부하 분산을 실현한다.

오브젝트 스토리지에서 파일 I/O는 네트워크를 통해 실행한다. 따라서 데이터의 양이 많을 때는 우수한 성능을 보이나, 소량의 데이터에 대해선 비효율적일 수 있다. 100B의 작은 파일을 자주 읽고 쓰는 것은 데이터 양에 비해 통신에서 발생하는 오버헤드가 너무 크기 때문이다. 

#### 데이터 수집

빅데이터에선 시계열 데이터를 자주 다룬다. 그러나 이것을 수시로 오브젝트 스토리지에 기록하면 작은 파일들이 대량으로 생성되어 시간이 지날수록 성능을 저하시키는 요인이 된다. 따라서 작은 데이터는 **어느 정도의 크기만큼 모아서 하나의 큰 파일**로 만드는 것이 효율적이다. 

반대로 파일 크기가 증가하면 네트워크 전송에 시간이 걸려 예상치 못한 오류 발생률도 높아진다. 따라서 이럴 때는 **데이터를 적당히 나누어** 문제를 해결할 수 있다. 

이렇게 수집한 데이터를 가공해서 집계 효율이 좋은 분산 스토리지를 만드는 프로세스를 **데이터 수집(data ingestion)**이라고 한다.

## 벌크 형의 데이터 전송

이미 축적된 대량 데이터가 있는 경우나, 기존 DB에서 데이터를 추출하고 싶을 경우에 벌크 형의 데이터 전송을 수행한다. 

원본 데이터가 처음부터 분산 스토리지에 저장되어 있는 것이 아니라면 데이터 전송을 위한 ETL 서버를 설치해야 한다. ETL 서버에는 structured data 처리에 적합한 데이터 웨어하우스 ETL 도구와 스크립트 등을 이용하여 데이터를 전송한다.

### 파일 사이즈 최적화

ETL 프로세스는 하루마다 또는 1시간 마다의 간격으로 정기적 실행을 하므로 축적된 데이터는 하나로 모인다. 워크플로 관리 도구를 활용하여 태스크의 크기 관리 및 실행을 쉽게 관리할 수 있다. 

### 데이터 전송의 워크플로

데이터 전송의 신뢰성이 중요한 경우라면 가능한 한 벌크 형 도구를 사용해야 한다. 스트리밍 형 데이터 전송은 추후 재실행이 어렵다. **과거의 데이터를 빠짐없이 가져오거나 실패한 작업을 재실행할 것을 고려한다면, 벌크 형 전송을 해야 한다.** 

## 스트리밍 형의 데이터 전송

지금 바로 생성되어 아직 어디에도 저장되지 않은 데이터는 그 자리에서 바로 전송해야 한다. 웹 브라우저, 모바일 앱, 센서 기기 등의 디바이스에서 데이터를 수집하는 경우를 고려해본다. 

이 전송의 공통점은 **다수의 클라이언트에서 계속해서 작은 데이터가 전송되는 것이다.** 이를 **메시지 배송(message delivery)**이라고 한다.

수신한 메시지를 저장하는 데에는 두 가지 방법이 있다. 하나는 NoSQL 데이터베이스를 이용해 Hive와 같은 쿼리 엔진으로 연결해 데이터를 읽어 들이는 것이다. 

다른 하나는, 분산 스토리지에 직접 쓰는 것이 아니라, **메시지 큐와 메시지 브로커** 등의 중계 시스템에 전송하는 방법이다. 이렇게 하는 경우, 기록된 데이터는 일정한 간격으로 꺼내고 모아서 함께 분산 스토리지에 저장한다. 

## 4-2 [성능x신뢰성] 메시지 딜리버리의 트레이드 오프

클라이언트 수가 늘어나면 스트리밍 타입의 메시지 딜리버리의 '성능'과 '신뢰성'을 둘 다 만족하기는 어렵게 된다. 메시지 브로커를 중심으로 하는 메시지 딜리버리의 구조와 그 한계에 대해 알아본다.

## 메시지 브로커

외부에서 보내오는 메시지 양을 제어할 수 없기 때문에 급격한 데이터 증가에 대응하는 것은 쉬운 일이 아니다. 쓰기의 빈도가 증가함에 따라 디스크 성능 한계에 도달해 더 쓸 수 없게 될 수도 있기 때문이다. 

만약 쓰기 성능 한계로 인해 오류가 발생하면, 대부분 클라이언트는 메시지를 재전송하려고 한다. 하지만 이 상황에선 아무리 재전송해도 오히려 부하만 높아질 뿐, 해결되는 것은 없으므로, 지속적으로 오류 상황에 빠질 수밖에 없다. 

따라서 대량의 메시지를 안정적으로 수신하기 위해서 빈번한 쓰기에도 잘 견딜 수 있는 성능이 높고, scalable한 스토리지가 필요하다. 그러나 이러한 스토리지가 언제나 있을거라고 확신할 수 없기 때문에, 데이터를 일시적으로 축적하는 미들웨어가 설치된다. 이를 메시지 브로커라 한다. 

분산형 메시지 브로커로 오픈 소스로는 **Apache Kafka**가 유명하며, 클라우드 서비스에선 Amazon Kinesis가 유명하다.

![Untitled](https://github.com/wookiist/til.wookiist.dev/blob/documentation/static/img/Data_Engineering/Introduction/message-broker.png?raw=true)

### PUSH & PULL

메시지 브로커는 데이터 쓰기 속도를 조정하기 위한 완충 부분이며, push에서 pull로 메시지 딜리버리 타이밍을 조절한다. (Q. 현재는 Kafka는 메시지 속도 조절 역할 뿐만 아니라 모든 메시지가 오고 가는 통로 역할도 하는 것으로 보이는데..)

### 메시지 라우팅

> 예를 들어, 어떤 시스템이 100만 대의 디바이스에서 1분마다 100B의 메시지를 수신한다고 가정하자. 시스템 전체가 받는 메시지는 초당 1.7만 메시지, 데이터는 1.66MB(=13.28Mbps)다. 데이터 크기만 보면 그리 많지는 않으나, 초당 1.7만 번의 쓰기에 견뎌야 하는 DB를 준비하기는 쉽지 않다.
> 

따라서, FE에선 메시지 브로커에 데이터를 Push하고 이를 Consumer가 모아서 가져온다. 예를 들어 1초마다 가져온다고 하면, 한 번에 가져오는 데이터의 크기는 1.66MB이므로 이 정도라면 실시간 처리하는 것은 그리 어렵지 않다. 이렇게 짧은 간격으로 차례대로 데이터를 꺼내어 처리하는 것이 Stream Processing이다. 

또한 메시지 브로커에 PUSH한 데이터는 여러 대의 다른 Consumer에서 Pull 할 수 있다. 이로써 메시지가 복사되어 데이터를 여러 경로로 분기할 수 있다. 이를 Message Routing이라 한다. 예를 들어, 메시지의 일부는 실시간 장애 감지를 위해 사용하면서 동시에 같은 메시지를 장기적인 데이터 분석을 위한 분산 스토리지에 저장하는 것도 가능하다. 이때 분산 스토리지로 저장할 땐 어느 정도 데이터를 모은 다음에 한꺼번에 파일로 저장하는 것이 좋다.

## 메시지 딜리버리를 확실하게 수행하는 것은 어렵다

성능 문제 외에도 피할 수 없는 것이 신뢰성(reliability)의 문제다. 모바일 환경처럼 신뢰성이 낮은 네트워크에서는 반드시 메시지의 중복이나 누락이 발생한다. 대부분 다음 중 하나를 보장하도록 시스템이 설계된다. 

- **at most once**
    
    → 메시지는 단 한 번만 전송된다. 그러나 전송 과정에서 실패하여 메시지가 사라질 가능성이 있다.(loss 발생)
    
- **exactly once**
    
    → 메시지가 손실되거나 중복될 이유 없이 딱 한 번만 전송된다.
    
- **at least once**
    
    → 메시지는 확실하게 전달한다. 그러나 같은 메시지가 여러 번 전달될 가능성이 있다.(중복 발생)
    

### at most once

데이터의 결손을 피하고자 대부분 retransmission을 수행한다. 하지만 retransmission이 존재하는 시스템에선 'at most once' 보장이 어렵다. 오류가 발생했다고 하더라도, '메시지가 발신되지 않았음'을 정의할 수는 없기 때문이다. 

### exactly once

코디네이터의 존재가 필수적이다. 그러나 분산 시스템에서 코디네이터가 항상 존재할 것이라고 가정할 수 없다. 코디네이터와의 연결이 끊어질 수도 있고, 코디네이터에 장애가 발생할 수도 있다. 이렇듯 코디네이터의 부재 상태에서 어떤 결정을 내릴 것인가에 대한 consensus가 이루어져야 하는데, 이 문제가 분산 시스템 설계에 있어서 어려운 문제 중 하나라고 알려져있고, 대부분 단시간 장애가 발생할 수 있다라는 가능성을 열어두고 구조를 설계하고 있다.

### at least once

deduplication 구조가 필요하다. 대부분의 message delivery 시스템은 'at least once'를 보장하나, 중복 제거는 이용자에게 맡기고 있어, 구현이 필요하다.

## Deduplication은 높은 비용의 작업

메시지 deduplication의 원리는 간단하다. 같은 메시지를 과거에 받은 적이 있는지에 대한 여부를 판정하는 것이다. 하지만 이 작업을 수행하면 성능 향상에 어려움이 있다. 따라서 몇 가지 대안을 통해 수행하고 있다.

### 오프셋을 이용한 중복 제거

각 메시지에 시작 위치(오프셋)을 적어 보내면, 메시지가 중복되어도 같은 장소에 덮어쓸 뿐이므로 문제가 되지 않는다. 이 방법은 벌크 형의 데이터 딜리버리처럼 데이터 크기가 고정된 경우에는 잘 작동한다. 그러나 스트리밍 형식의 메시지 딜리버리에선 거의 사용하지 않는다.

### 고유 ID에 의한 중복 제거

스트리밍 형의 메시지 딜리버리에서 자주 사용되는 방법으로, 모든 메시지에 UUID (Universally Unique IDentifier) 등의 고유 ID를 지정하는 것이다. 다만 메시지에 증가에 따라 ID도 증가하므로, 관리의 문제가 있다. 

> 과거의 모든 ID를 기억하는 것은 비현실적이고, ID를 파기하면 늦게 도착한 메시지가 중복될 수 있다. 현실적으론 최근에 받은 ID만을 기록(최근 1시간 이내 등)하고 그보다 늦게 온 메시지의 중복은 허용한다. 중복의 대부분은 일시적인 통신 오류로 인해 발생하기 때문에 그것만 제거하면 99% 신뢰도는 달성할 수 있다.
> 

### End-to-End 신뢰성

빅데이터의 메시지 딜리버리에선 종종 신뢰성보단 '효율'이 중시된다. **따라서, 중간 경로에 'at least once'를 보장하는 한편, '중복 제거는 하지 않는 것'**이 표준적인 구현이다. 중복 제거는 종단 간에서 수행하지 않으면 의미가 없기 때문이다. 그러나 메시지 딜리버리의 최종 신뢰성은 중간 경로의 신뢰성 조합으로 결정된다. 중간에 한 부분이라도 'at most once'가 있으면 메시지를 빠뜨릴 가능성이 있고, 'at least once'가 있으면 중복이 발생할 수도 있다. 따라서 신뢰성을 높이려면 중간 경로를 모두 'at least once'로 통일하고, 고유 ID를 부여하여 경로의 End에서 중복 제거를 수행해야 한다.

## 데이터 수집 파이프라인

일련의 프로세스를 거쳐, 데이터를 구조화하고 열 지향 스토리지로 변환함으로써, 장기간 데이터 분석에 적합한 스토리지를 완성하였다.

![Untitled](https://github.com/wookiist/til.wookiist.dev/blob/documentation/static/img/Data_Engineering/Introduction/streaming_data_pipeline.png?raw=true)

물론 요구 사항에 따라 중복이 허용된다면 중복 제거 컴포넌트를 제거하면 되고, 쓰기 성능이 충분히 신뢰할 수 있다면 메시지 브로커를 제거해도 된다. 이러한 과정은 워크플로에서 후에 다룬다.

### 중복을 고려한 시스템 설계

일반적으로 스트리밍 형의 데이터 딜리버리에는 항상 중복의 가능성이 있다고 생각하는 것이 편하다. 일반적으로 데이터 센터와 같은 안정된 회선이라면 아무것도 하지 않고도 99% 이상의 신뢰성을 확보할 가능성이 높다. 그리고 그 정도의 오차는 허용한 후에 평소 '멱등한 조작'에 유의하여 '중복이 있어도 문제가 되지 않는' 시스템 설계를 할 것을 추천한다.

> 신뢰성이 중시되는 경우에는 스트리밍 형 프로세싱을 피하는 것이 가장 좋다. 예를 들어, 과금 데이터처럼 오차가 허용될 수 없는 것에는 트랜잭션 처리를 지원하는 데이터베이스에 애플리케이션이 직접 기록하고, 벌크 프로세싱을 함으로써 중복도 결손도 확실하게 피해야 할 것이다.
>