---
id: 'de-intro-4'
title: 'CH4 - 빅데이터의 축적'
---

## 벌크 형과 스트리밍 형의 데이터 수집

데이터를 전송하는 데는 벌크 형과 스트리밍 형, 두 종류의 도구가 사용된다. 

### 객체 스토리지와 데이터 수집

빅데이터는 대부분 확장성이 높은 **분산 스토리지**에 저장된다. 그리고 일반적으로 **오브젝트 스토리지(객체 스토리지)**를 활용한다. 대표적으로 Hadoop의 HDFS나 Amazon의 Amazon S3가 유명하다.

![Untitled](https://github.com/wookiist/til.wookiist.dev/blob/documentation/static/img/Data_Engineering/Introduction/object_storage.png?raw=true)

오브젝트 스토리지는 여러 노드를 사용해 파일을 여러 디스크에 복사해둠으로써 데이터 중복화와 부하 분산을 실현한다.

오브젝트 스토리지에서 파일 I/O는 네트워크를 통해 실행한다. 따라서 데이터의 양이 많을 때는 우수한 성능을 보이나, 소량의 데이터에 대해선 비효율적일 수 있다. 100B의 작은 파일을 자주 읽고 쓰는 것은 데이터 양에 비해 통신에서 발생하는 오버헤드가 너무 크기 때문이다. 

#### 데이터 수집

빅데이터에선 시계열 데이터를 자주 다룬다. 그러나 이것을 수시로 오브젝트 스토리지에 기록하면 작은 파일들이 대량으로 생성되어 시간이 지날수록 성능을 저하시키는 요인이 된다. 따라서 작은 데이터는 **어느 정도의 크기만큼 모아서 하나의 큰 파일**로 만드는 것이 효율적이다. 

반대로 파일 크기가 증가하면 네트워크 전송에 시간이 걸려 예상치 못한 오류 발생률도 높아진다. 따라서 이럴 때는 **데이터를 적당히 나누어** 문제를 해결할 수 있다. 

이렇게 수집한 데이터를 가공해서 집계 효율이 좋은 분산 스토리지를 만드는 프로세스를 **데이터 수집(data ingestion)**이라고 한다.

## 벌크 형의 데이터 전송

이미 축적된 대량 데이터가 있는 경우나, 기존 DB에서 데이터를 추출하고 싶을 경우에 벌크 형의 데이터 전송을 수행한다. 

원본 데이터가 처음부터 분산 스토리지에 저장되어 있는 것이 아니라면 데이터 전송을 위한 ETL 서버를 설치해야 한다. ETL 서버에는 structured data 처리에 적합한 데이터 웨어하우스 ETL 도구와 스크립트 등을 이용하여 데이터를 전송한다.

### 파일 사이즈 최적화

ETL 프로세스는 하루마다 또는 1시간 마다의 간격으로 정기적 실행을 하므로 축적된 데이터는 하나로 모인다. 워크플로 관리 도구를 활용하여 태스크의 크기 관리 및 실행을 쉽게 관리할 수 있다. 

### 데이터 전송의 워크플로

데이터 전송의 신뢰성이 중요한 경우라면 가능한 한 벌크 형 도구를 사용해야 한다. 스트리밍 형 데이터 전송은 추후 재실행이 어렵다. **과거의 데이터를 빠짐없이 가져오거나 실패한 작업을 재실행할 것을 고려한다면, 벌크 형 전송을 해야 한다.** 

## 스트리밍 형의 데이터 전송

지금 바로 생성되어 아직 어디에도 저장되지 않은 데이터는 그 자리에서 바로 전송해야 한다. 웹 브라우저, 모바일 앱, 센서 기기 등의 디바이스에서 데이터를 수집하는 경우를 고려해본다. 

이 전송의 공통점은 **다수의 클라이언트에서 계속해서 작은 데이터가 전송되는 것이다.** 이를 **메시지 배송(message delivery)**이라고 한다.

수신한 메시지를 저장하는 데에는 두 가지 방법이 있다. 하나는 NoSQL 데이터베이스를 이용해 Hive와 같은 쿼리 엔진으로 연결해 데이터를 읽어 들이는 것이다. 

다른 하나는, 분산 스토리지에 직접 쓰는 것이 아니라, **메시지 큐와 메시지 브로커** 등의 중계 시스템에 전송하는 방법이다. 이렇게 하는 경우, 기록된 데이터는 일정한 간격으로 꺼내고 모아서 함께 분산 스토리지에 저장한다. 

## 4-2 [성능x신뢰성] 메시지 딜리버리의 트레이드 오프

클라이언트 수가 늘어나면 스트리밍 타입의 메시지 딜리버리의 '성능'과 '신뢰성'을 둘 다 만족하기는 어렵게 된다. 메시지 브로커를 중심으로 하는 메시지 딜리버리의 구조와 그 한계에 대해 알아본다.

## 메시지 브로커

외부에서 보내오는 메시지 양을 제어할 수 없기 때문에 급격한 데이터 증가에 대응하는 것은 쉬운 일이 아니다. 쓰기의 빈도가 증가함에 따라 디스크 성능 한계에 도달해 더 쓸 수 없게 될 수도 있기 때문이다. 

만약 쓰기 성능 한계로 인해 오류가 발생하면, 대부분 클라이언트는 메시지를 재전송하려고 한다. 하지만 이 상황에선 아무리 재전송해도 오히려 부하만 높아질 뿐, 해결되는 것은 없으므로, 지속적으로 오류 상황에 빠질 수밖에 없다. 

따라서 대량의 메시지를 안정적으로 수신하기 위해서 빈번한 쓰기에도 잘 견딜 수 있는 성능이 높고, scalable한 스토리지가 필요하다. 그러나 이러한 스토리지가 언제나 있을거라고 확신할 수 없기 때문에, 데이터를 일시적으로 축적하는 미들웨어가 설치된다. 이를 메시지 브로커라 한다. 

분산형 메시지 브로커로 오픈 소스로는 **Apache Kafka**가 유명하며, 클라우드 서비스에선 Amazon Kinesis가 유명하다.

![Untitled](https://github.com/wookiist/til.wookiist.dev/blob/documentation/static/img/Data_Engineering/Introduction/message-broker.png?raw=true)

### PUSH & PULL

메시지 브로커는 데이터 쓰기 속도를 조정하기 위한 완충 부분이며, push에서 pull로 메시지 딜리버리 타이밍을 조절한다. (Q. 현재는 Kafka는 메시지 속도 조절 역할 뿐만 아니라 모든 메시지가 오고 가는 통로 역할도 하는 것으로 보이는데..)

### 메시지 라우팅

> 예를 들어, 어떤 시스템이 100만 대의 디바이스에서 1분마다 100B의 메시지를 수신한다고 가정하자. 시스템 전체가 받는 메시지는 초당 1.7만 메시지, 데이터는 1.66MB(=13.28Mbps)다. 데이터 크기만 보면 그리 많지는 않으나, 초당 1.7만 번의 쓰기에 견뎌야 하는 DB를 준비하기는 쉽지 않다.
> 

따라서, FE에선 메시지 브로커에 데이터를 Push하고 이를 Consumer가 모아서 가져온다. 예를 들어 1초마다 가져온다고 하면, 한 번에 가져오는 데이터의 크기는 1.66MB이므로 이 정도라면 실시간 처리하는 것은 그리 어렵지 않다. 이렇게 짧은 간격으로 차례대로 데이터를 꺼내어 처리하는 것이 Stream Processing이다. 

또한 메시지 브로커에 PUSH한 데이터는 여러 대의 다른 Consumer에서 Pull 할 수 있다. 이로써 메시지가 복사되어 데이터를 여러 경로로 분기할 수 있다. 이를 Message Routing이라 한다. 예를 들어, 메시지의 일부는 실시간 장애 감지를 위해 사용하면서 동시에 같은 메시지를 장기적인 데이터 분석을 위한 분산 스토리지에 저장하는 것도 가능하다. 이때 분산 스토리지로 저장할 땐 어느 정도 데이터를 모은 다음에 한꺼번에 파일로 저장하는 것이 좋다.