<!doctype html>
<html class="docs-version-current" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.6">
<title data-react-helmet="true">CH4 - 빅데이터의 축적 | wookiist TIL</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://til.wookiist.dev/Data Engineering/Introduction/de-intro-4"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="CH4 - 빅데이터의 축적 | wookiist TIL"><meta data-react-helmet="true" name="description" content="벌크 형과 스트리밍 형의 데이터 수집"><meta data-react-helmet="true" property="og:description" content="벌크 형과 스트리밍 형의 데이터 수집"><link data-react-helmet="true" rel="shortcut icon" href="/img/wookii.ico"><link data-react-helmet="true" rel="canonical" href="https://til.wookiist.dev/Data Engineering/Introduction/de-intro-4"><link data-react-helmet="true" rel="alternate" href="https://til.wookiist.dev/Data Engineering/Introduction/de-intro-4" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://til.wookiist.dev/Data Engineering/Introduction/de-intro-4" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.3a6fe04e.css">
<link rel="preload" href="/assets/js/runtime~main.af4d6fe8.js" as="script">
<link rel="preload" href="/assets/js/main.40a9dcb1.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_1oUP">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><img src="/img/logo.svg" alt="wookiist TIL" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/img/logo.svg" alt="wookiist TIL" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><b class="navbar__title">wookiist TIL</b></a><a class="navbar__item navbar__link navbar__link--active" href="/">Docs</a></div><div class="navbar__items navbar__items--right"><a href="https://wookiist.dev" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>Blog<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><a href="https://github.com/wookiist" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="react-toggle toggle_3Zt9 react-toggle--disabled"><div class="react-toggle-track" role="button" tabindex="-1"><div class="react-toggle-track-check"><span class="toggle_71bT">🌜</span></div><div class="react-toggle-track-x"><span class="toggle_71bT">🌞</span></div><div class="react-toggle-thumb"></div></div><input type="checkbox" class="react-toggle-screenreader-only" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_31aa"><button class="clean-btn backToTopButton_35hR" type="button"><svg viewBox="0 0 24 24" width="28"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z" fill="currentColor"></path></svg></button><aside class="docSidebarContainer_3Kbt"><div class="sidebar_15mo"><nav class="menu thin-scrollbar menu_Bmed menuWithAnnouncementBar_2WvA"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" href="/">MAIN</a></li><li class="theme-doc-sidebar-item-category menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#">Data Engineering</a><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#" tabindex="0">Airflow</a></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#" tabindex="0">Druid</a></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#" tabindex="0">Flink</a></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#" tabindex="0">Hadoop</a></li><li class="theme-doc-sidebar-item-category menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#" tabindex="0">Introduction</a><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/Data Engineering/Introduction/de-terms">Data Engineering Terms</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/Data Engineering/Introduction/de-intro-1">CH1 - 빅데이터의 기초 지식</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/Data Engineering/Introduction/de-intro-2">CH2 - 빅데이터의 탐색</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Data Engineering/Introduction/de-intro-4">CH4 - 빅데이터의 축적</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/Data Engineering/Introduction/de-intro-5">CH5 - 빅데이터의 파이프라인</a></li></ul></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#" tabindex="0">Spark</a></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#" tabindex="0">Sqoop</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/Data Engineering/data-pipeline-components">데이터 파이프라인 요소 정리</a></li></ul></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">Linux</a></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">SQL</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" href="/test">test</a></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">wookiist</a></li></ul></nav></div></aside><main class="docMainContainer_3ufF"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_3FnS"><div class="docItemContainer_33ec"><article><div class="tocCollapsible_1PrD theme-doc-toc-mobile tocMobile_3Hoh"><button type="button" class="clean-btn tocCollapsibleButton_2O1e">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>CH4 - 빅데이터의 축적</h1></header><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="벌크-형과-스트리밍-형의-데이터-수집"></a>벌크 형과 스트리밍 형의 데이터 수집<a class="hash-link" href="#벌크-형과-스트리밍-형의-데이터-수집" title="Direct link to heading">#</a></h2><p>데이터를 전송하는 데는 벌크 형과 스트리밍 형, 두 종류의 도구가 사용된다. </p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="객체-스토리지와-데이터-수집"></a>객체 스토리지와 데이터 수집<a class="hash-link" href="#객체-스토리지와-데이터-수집" title="Direct link to heading">#</a></h3><p>빅데이터는 대부분 확장성이 높은 <strong>분산 스토리지</strong>에 저장된다. 그리고 일반적으로 <strong>오브젝트 스토리지(객체 스토리지)</strong>를 활용한다. 대표적으로 Hadoop의 HDFS나 Amazon의 Amazon S3가 유명하다.</p><p><img src="https://github.com/wookiist/til.wookiist.dev/blob/documentation/static/img/Data_Engineering/Introduction/object_storage.png?raw=true" alt="Untitled"></p><p>오브젝트 스토리지는 여러 노드를 사용해 파일을 여러 디스크에 복사해둠으로써 데이터 중복화와 부하 분산을 실현한다.</p><p>오브젝트 스토리지에서 파일 I/O는 네트워크를 통해 실행한다. 따라서 데이터의 양이 많을 때는 우수한 성능을 보이나, 소량의 데이터에 대해선 비효율적일 수 있다. 100B의 작은 파일을 자주 읽고 쓰는 것은 데이터 양에 비해 통신에서 발생하는 오버헤드가 너무 크기 때문이다. </p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_31ik" id="데이터-수집"></a>데이터 수집<a class="hash-link" href="#데이터-수집" title="Direct link to heading">#</a></h4><p>빅데이터에선 시계열 데이터를 자주 다룬다. 그러나 이것을 수시로 오브젝트 스토리지에 기록하면 작은 파일들이 대량으로 생성되어 시간이 지날수록 성능을 저하시키는 요인이 된다. 따라서 작은 데이터는 <strong>어느 정도의 크기만큼 모아서 하나의 큰 파일</strong>로 만드는 것이 효율적이다. </p><p>반대로 파일 크기가 증가하면 네트워크 전송에 시간이 걸려 예상치 못한 오류 발생률도 높아진다. 따라서 이럴 때는 <strong>데이터를 적당히 나누어</strong> 문제를 해결할 수 있다. </p><p>이렇게 수집한 데이터를 가공해서 집계 효율이 좋은 분산 스토리지를 만드는 프로세스를 <strong>데이터 수집(data ingestion)</strong>이라고 한다.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="벌크-형의-데이터-전송"></a>벌크 형의 데이터 전송<a class="hash-link" href="#벌크-형의-데이터-전송" title="Direct link to heading">#</a></h2><p>이미 축적된 대량 데이터가 있는 경우나, 기존 DB에서 데이터를 추출하고 싶을 경우에 벌크 형의 데이터 전송을 수행한다. </p><p>원본 데이터가 처음부터 분산 스토리지에 저장되어 있는 것이 아니라면 데이터 전송을 위한 ETL 서버를 설치해야 한다. ETL 서버에는 structured data 처리에 적합한 데이터 웨어하우스 ETL 도구와 스크립트 등을 이용하여 데이터를 전송한다.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="파일-사이즈-최적화"></a>파일 사이즈 최적화<a class="hash-link" href="#파일-사이즈-최적화" title="Direct link to heading">#</a></h3><p>ETL 프로세스는 하루마다 또는 1시간 마다의 간격으로 정기적 실행을 하므로 축적된 데이터는 하나로 모인다. 워크플로 관리 도구를 활용하여 태스크의 크기 관리 및 실행을 쉽게 관리할 수 있다. </p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="데이터-전송의-워크플로"></a>데이터 전송의 워크플로<a class="hash-link" href="#데이터-전송의-워크플로" title="Direct link to heading">#</a></h3><p>데이터 전송의 신뢰성이 중요한 경우라면 가능한 한 벌크 형 도구를 사용해야 한다. 스트리밍 형 데이터 전송은 추후 재실행이 어렵다. <strong>과거의 데이터를 빠짐없이 가져오거나 실패한 작업을 재실행할 것을 고려한다면, 벌크 형 전송을 해야 한다.</strong> </p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="스트리밍-형의-데이터-전송"></a>스트리밍 형의 데이터 전송<a class="hash-link" href="#스트리밍-형의-데이터-전송" title="Direct link to heading">#</a></h2><p>지금 바로 생성되어 아직 어디에도 저장되지 않은 데이터는 그 자리에서 바로 전송해야 한다. 웹 브라우저, 모바일 앱, 센서 기기 등의 디바이스에서 데이터를 수집하는 경우를 고려해본다. </p><p>이 전송의 공통점은 <strong>다수의 클라이언트에서 계속해서 작은 데이터가 전송되는 것이다.</strong> 이를 <strong>메시지 배송(message delivery)</strong>이라고 한다.</p><p>수신한 메시지를 저장하는 데에는 두 가지 방법이 있다. 하나는 NoSQL 데이터베이스를 이용해 Hive와 같은 쿼리 엔진으로 연결해 데이터를 읽어 들이는 것이다. </p><p>다른 하나는, 분산 스토리지에 직접 쓰는 것이 아니라, <strong>메시지 큐와 메시지 브로커</strong> 등의 중계 시스템에 전송하는 방법이다. 이렇게 하는 경우, 기록된 데이터는 일정한 간격으로 꺼내고 모아서 함께 분산 스토리지에 저장한다. </p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="4-2-성능x신뢰성-메시지-딜리버리의-트레이드-오프"></a>4-2 [성능x신뢰성] 메시지 딜리버리의 트레이드 오프<a class="hash-link" href="#4-2-성능x신뢰성-메시지-딜리버리의-트레이드-오프" title="Direct link to heading">#</a></h2><p>클라이언트 수가 늘어나면 스트리밍 타입의 메시지 딜리버리의 &#x27;성능&#x27;과 &#x27;신뢰성&#x27;을 둘 다 만족하기는 어렵게 된다. 메시지 브로커를 중심으로 하는 메시지 딜리버리의 구조와 그 한계에 대해 알아본다.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="메시지-브로커"></a>메시지 브로커<a class="hash-link" href="#메시지-브로커" title="Direct link to heading">#</a></h2><p>외부에서 보내오는 메시지 양을 제어할 수 없기 때문에 급격한 데이터 증가에 대응하는 것은 쉬운 일이 아니다. 쓰기의 빈도가 증가함에 따라 디스크 성능 한계에 도달해 더 쓸 수 없게 될 수도 있기 때문이다. </p><p>만약 쓰기 성능 한계로 인해 오류가 발생하면, 대부분 클라이언트는 메시지를 재전송하려고 한다. 하지만 이 상황에선 아무리 재전송해도 오히려 부하만 높아질 뿐, 해결되는 것은 없으므로, 지속적으로 오류 상황에 빠질 수밖에 없다. </p><p>따라서 대량의 메시지를 안정적으로 수신하기 위해서 빈번한 쓰기에도 잘 견딜 수 있는 성능이 높고, scalable한 스토리지가 필요하다. 그러나 이러한 스토리지가 언제나 있을거라고 확신할 수 없기 때문에, 데이터를 일시적으로 축적하는 미들웨어가 설치된다. 이를 메시지 브로커라 한다. </p><p>분산형 메시지 브로커로 오픈 소스로는 <strong>Apache Kafka</strong>가 유명하며, 클라우드 서비스에선 Amazon Kinesis가 유명하다.</p><p><img src="https://github.com/wookiist/til.wookiist.dev/blob/documentation/static/img/Data_Engineering/Introduction/message-broker.png?raw=true" alt="Untitled"></p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="push--pull"></a>PUSH &amp; PULL<a class="hash-link" href="#push--pull" title="Direct link to heading">#</a></h3><p>메시지 브로커는 데이터 쓰기 속도를 조정하기 위한 완충 부분이며, push에서 pull로 메시지 딜리버리 타이밍을 조절한다. (Q. 현재는 Kafka는 메시지 속도 조절 역할 뿐만 아니라 모든 메시지가 오고 가는 통로 역할도 하는 것으로 보이는데..)</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="메시지-라우팅"></a>메시지 라우팅<a class="hash-link" href="#메시지-라우팅" title="Direct link to heading">#</a></h3><blockquote><p>예를 들어, 어떤 시스템이 100만 대의 디바이스에서 1분마다 100B의 메시지를 수신한다고 가정하자. 시스템 전체가 받는 메시지는 초당 1.7만 메시지, 데이터는 1.66MB(=13.28Mbps)다. 데이터 크기만 보면 그리 많지는 않으나, 초당 1.7만 번의 쓰기에 견뎌야 하는 DB를 준비하기는 쉽지 않다.</p></blockquote><p>따라서, FE에선 메시지 브로커에 데이터를 Push하고 이를 Consumer가 모아서 가져온다. 예를 들어 1초마다 가져온다고 하면, 한 번에 가져오는 데이터의 크기는 1.66MB이므로 이 정도라면 실시간 처리하는 것은 그리 어렵지 않다. 이렇게 짧은 간격으로 차례대로 데이터를 꺼내어 처리하는 것이 Stream Processing이다. </p><p>또한 메시지 브로커에 PUSH한 데이터는 여러 대의 다른 Consumer에서 Pull 할 수 있다. 이로써 메시지가 복사되어 데이터를 여러 경로로 분기할 수 있다. 이를 Message Routing이라 한다. 예를 들어, 메시지의 일부는 실시간 장애 감지를 위해 사용하면서 동시에 같은 메시지를 장기적인 데이터 분석을 위한 분산 스토리지에 저장하는 것도 가능하다. 이때 분산 스토리지로 저장할 땐 어느 정도 데이터를 모은 다음에 한꺼번에 파일로 저장하는 것이 좋다.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="메시지-딜리버리를-확실하게-수행하는-것은-어렵다"></a>메시지 딜리버리를 확실하게 수행하는 것은 어렵다<a class="hash-link" href="#메시지-딜리버리를-확실하게-수행하는-것은-어렵다" title="Direct link to heading">#</a></h2><p>성능 문제 외에도 피할 수 없는 것이 신뢰성(reliability)의 문제다. 모바일 환경처럼 신뢰성이 낮은 네트워크에서는 반드시 메시지의 중복이나 누락이 발생한다. 대부분 다음 중 하나를 보장하도록 시스템이 설계된다. </p><ul><li><strong>at most once</strong>  → 메시지는 단 한 번만 전송된다. 그러나 전송 과정에서 실패하여 메시지가 사라질 가능성이 있다.(loss 발생)
</li><li><strong>exactly once</strong>  → 메시지가 손실되거나 중복될 이유 없이 딱 한 번만 전송된다.
</li><li><strong>at least once</strong>  → 메시지는 확실하게 전달한다. 그러나 같은 메시지가 여러 번 전달될 가능성이 있다.(중복 발생)
</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="at-most-once"></a>at most once<a class="hash-link" href="#at-most-once" title="Direct link to heading">#</a></h3><p>데이터의 결손을 피하고자 대부분 retransmission을 수행한다. 하지만 retransmission이 존재하는 시스템에선 &#x27;at most once&#x27; 보장이 어렵다. 오류가 발생했다고 하더라도, &#x27;메시지가 발신되지 않았음&#x27;을 정의할 수는 없기 때문이다. </p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="exactly-once"></a>exactly once<a class="hash-link" href="#exactly-once" title="Direct link to heading">#</a></h3><p>코디네이터의 존재가 필수적이다. 그러나 분산 시스템에서 코디네이터가 항상 존재할 것이라고 가정할 수 없다. 코디네이터와의 연결이 끊어질 수도 있고, 코디네이터에 장애가 발생할 수도 있다. 이렇듯 코디네이터의 부재 상태에서 어떤 결정을 내릴 것인가에 대한 consensus가 이루어져야 하는데, 이 문제가 분산 시스템 설계에 있어서 어려운 문제 중 하나라고 알려져있고, 대부분 단시간 장애가 발생할 수 있다라는 가능성을 열어두고 구조를 설계하고 있다.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="at-least-once"></a>at least once<a class="hash-link" href="#at-least-once" title="Direct link to heading">#</a></h3><p>deduplication 구조가 필요하다. 대부분의 message delivery 시스템은 &#x27;at least once&#x27;를 보장하나, 중복 제거는 이용자에게 맡기고 있어, 구현이 필요하다.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="deduplication은-높은-비용의-작업"></a>Deduplication은 높은 비용의 작업<a class="hash-link" href="#deduplication은-높은-비용의-작업" title="Direct link to heading">#</a></h2><p>메시지 deduplication의 원리는 간단하다. 같은 메시지를 과거에 받은 적이 있는지에 대한 여부를 판정하는 것이다. 하지만 이 작업을 수행하면 성능 향상에 어려움이 있다. 따라서 몇 가지 대안을 통해 수행하고 있다.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="오프셋을-이용한-중복-제거"></a>오프셋을 이용한 중복 제거<a class="hash-link" href="#오프셋을-이용한-중복-제거" title="Direct link to heading">#</a></h3><p>각 메시지에 시작 위치(오프셋)을 적어 보내면, 메시지가 중복되어도 같은 장소에 덮어쓸 뿐이므로 문제가 되지 않는다. 이 방법은 벌크 형의 데이터 딜리버리처럼 데이터 크기가 고정된 경우에는 잘 작동한다. 그러나 스트리밍 형식의 메시지 딜리버리에선 거의 사용하지 않는다.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="고유-id에-의한-중복-제거"></a>고유 ID에 의한 중복 제거<a class="hash-link" href="#고유-id에-의한-중복-제거" title="Direct link to heading">#</a></h3><p>스트리밍 형의 메시지 딜리버리에서 자주 사용되는 방법으로, 모든 메시지에 UUID (Universally Unique IDentifier) 등의 고유 ID를 지정하는 것이다. 다만 메시지에 증가에 따라 ID도 증가하므로, 관리의 문제가 있다. </p><blockquote><p>과거의 모든 ID를 기억하는 것은 비현실적이고, ID를 파기하면 늦게 도착한 메시지가 중복될 수 있다. 현실적으론 최근에 받은 ID만을 기록(최근 1시간 이내 등)하고 그보다 늦게 온 메시지의 중복은 허용한다. 중복의 대부분은 일시적인 통신 오류로 인해 발생하기 때문에 그것만 제거하면 99% 신뢰도는 달성할 수 있다.</p></blockquote><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="end-to-end-신뢰성"></a>End-to-End 신뢰성<a class="hash-link" href="#end-to-end-신뢰성" title="Direct link to heading">#</a></h3><p>빅데이터의 메시지 딜리버리에선 종종 신뢰성보단 &#x27;효율&#x27;이 중시된다. <strong>따라서, 중간 경로에 &#x27;at least once&#x27;를 보장하는 한편, &#x27;중복 제거는 하지 않는 것&#x27;</strong>이 표준적인 구현이다. 중복 제거는 종단 간에서 수행하지 않으면 의미가 없기 때문이다. 그러나 메시지 딜리버리의 최종 신뢰성은 중간 경로의 신뢰성 조합으로 결정된다. 중간에 한 부분이라도 &#x27;at most once&#x27;가 있으면 메시지를 빠뜨릴 가능성이 있고, &#x27;at least once&#x27;가 있으면 중복이 발생할 수도 있다. 따라서 신뢰성을 높이려면 중간 경로를 모두 &#x27;at least once&#x27;로 통일하고, 고유 ID를 부여하여 경로의 End에서 중복 제거를 수행해야 한다.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="데이터-수집-파이프라인"></a>데이터 수집 파이프라인<a class="hash-link" href="#데이터-수집-파이프라인" title="Direct link to heading">#</a></h2><p>일련의 프로세스를 거쳐, 데이터를 구조화하고 열 지향 스토리지로 변환함으로써, 장기간 데이터 분석에 적합한 스토리지를 완성하였다.</p><p><img src="https://github.com/wookiist/til.wookiist.dev/blob/documentation/static/img/Data_Engineering/Introduction/streaming_data_pipeline.png?raw=true" alt="Untitled"></p><p>물론 요구 사항에 따라 중복이 허용된다면 중복 제거 컴포넌트를 제거하면 되고, 쓰기 성능이 충분히 신뢰할 수 있다면 메시지 브로커를 제거해도 된다. 이러한 과정은 워크플로에서 후에 다룬다.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="중복을-고려한-시스템-설계"></a>중복을 고려한 시스템 설계<a class="hash-link" href="#중복을-고려한-시스템-설계" title="Direct link to heading">#</a></h3><p>일반적으로 스트리밍 형의 데이터 딜리버리에는 항상 중복의 가능성이 있다고 생각하는 것이 편하다. 일반적으로 데이터 센터와 같은 안정된 회선이라면 아무것도 하지 않고도 99% 이상의 신뢰성을 확보할 가능성이 높다. 그리고 그 정도의 오차는 허용한 후에 평소 &#x27;멱등한 조작&#x27;에 유의하여 &#x27;중복이 있어도 문제가 되지 않는&#x27; 시스템 설계를 할 것을 추천한다.</p><blockquote><p>신뢰성이 중시되는 경우에는 스트리밍 형 프로세싱을 피하는 것이 가장 좋다. 예를 들어, 과금 데이터처럼 오차가 허용될 수 없는 것에는 트랜잭션 처리를 지원하는 데이터베이스에 애플리케이션이 직접 기록하고, 벌크 프로세싱을 함으로써 중복도 결손도 확실하게 피해야 할 것이다.</p></blockquote><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="4-3-시계열-데이터의-최적화"></a>4-3 시계열 데이터의 최적화<a class="hash-link" href="#4-3-시계열-데이터의-최적화" title="Direct link to heading">#</a></h2><p>스트리밍 프로세싱에서 메시지 딜리버리를 할 땐 &#x27;메시지가 발생하여 도착할 때까지의 시간 지연&#x27;이 문제가 된다. </p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="프로세스-시간과-이벤트-시간"></a>프로세스 시간과 이벤트 시간<a class="hash-link" href="#프로세스-시간과-이벤트-시간" title="Direct link to heading">#</a></h2><p>결론부터 말하자면 데이터 분석의 대상은 주로 이벤트 시간이 된다. </p><ul><li>이벤트 시간(Event time) : 클라이언트 상에서 메시지가 <strong>생성된 시간</strong></li><li>프로세스 시간(Process time) : 서버에서 메시지를 <strong>처리하는 시간</strong></li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="프로세스-시간에-의한-분할과-문제점"></a>프로세스 시간에 의한 분할과 문제점<a class="hash-link" href="#프로세스-시간에-의한-분할과-문제점" title="Direct link to heading">#</a></h2><p>이벤트의 대부분은 그날 바로 보내오지만, 전날 또는 그 이전에 생성된 이벤트도 많이 도달한다. 따라서 특정한 날에 발생한 모든 이벤트를 수집하려면 며칠 동안 기다려야 한다. </p><p>반면에 분산 스토리지에 데이터를 넣을 땐 <strong>이벤트 시간이 아닌 프로세스 시간을 사용하는 것</strong>이 일반적이다. </p><p>예를 들어, 1월 1일에 발생한 이벤트라면, 1월 1일 이후에 만들어진 모든 파일(1월 2일 파일, 1월 3일 파일, 1월 31일 파일..)에 포함되어 있을 수 있다. 따라서 1개월 후인 2월 1일에 지금까지 만들어진 모든 파일을 열고 거기서 1월 1일 데이터만 뽑아내면 비교적 정확한 결과를 얻을 수 있다. </p><p>하지만 데이터가 이벤트 시간으로 정렬되어 있지 않기 때문에 모든 데이터를 로드해서 이벤트 시간이 포함되어 있는지를 판단해야 하는, Full Scan을 수행하게 되는데 이것이 시스템 부하를 크게 높이게 된다. 이는 가능한 한 피하고 싶을 것이다.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="시계열-인덱스"></a>시계열 인덱스<a class="hash-link" href="#시계열-인덱스" title="Direct link to heading">#</a></h2><p>앞선 상황을 피하고자 이벤트 시간 취급을 효율적으로 하기 위해 데이터를 정렬하는 것을 고려해볼 필요가 있다. 예를 들어, Cassandra와 같은 시계열 인덱스에 대응하는 분산 DB를 이용하면 이벤트 시간으로 인덱싱 된 테이블을 처음부터 만들 수 있다. </p><p>한편, 장기간에 걸쳐 대량의 데이터를 집계해야 하는 경우라면, 분산 DB가 그리 효율적이지 않다. 장기적인 데이터 분석에는 집계 효율이 높은 columnar storage를 지속적으로 만들 필요가 있다. </p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="조건절-푸시다운"></a>조건절 푸시다운<a class="hash-link" href="#조건절-푸시다운" title="Direct link to heading">#</a></h2><p>하루에 한 번씩 새로 도착한 데이터를 배치 작업으로 변환하는 것을 고려해본다. 최초에 (예를 들어, 기존 데이터가 도착한 순서로 정렬되어 있던 CSV 파일을) 이벤트 시간으로 데이터를 정렬한 후에 columnar storage로 변환한다. </p><p>columnar storage는 &#x27;칼럼 단위의 통계 정보&#x27;를 이용해 최적화를 수행한다. </p><blockquote><p>예를 들어, 시간이 정보라면, 각 칼럼의 최솟값(시작 시각)과 최댓값(종료 시각) 등이 모든 파일에 메타 정보로 저장되어 있으며, 해당 정보를 참고해서 어떤 파일의 어떤 부분에 원하는 데이터가 포함되어 있는지를 파악할 수 있다.</p></blockquote><p>이 통계 정보를 이용해서 최소한의 필요로하는 데이터만을 읽도록 하는 최적화 방법을 &#x27;조건절 푸시 다운&#x27;이라고 한다. (predicate pushdown) </p><p>columnar storage를 만들 때, 가급적 읽어들이는 데이터의 양을 최소화할 수 있도록 데이터를 정렬해둠으로써 predicate pushdown에 의한 최적화가 작동해 풀 스캔을 피할 수 있도록 한다.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="이벤트-시간에-의한-분할"></a>이벤트 시간에 의한 분할<a class="hash-link" href="#이벤트-시간에-의한-분할" title="Direct link to heading">#</a></h2><p>처음부터 프로세스 시간으로 파일을 나누고 있는 한, 같은 이벤트 시간에 발생한 데이터가 여러 파일에 분산될 수밖에 없다. 따라서 정말 많은 파일들을 열어봐야 한다는 문제가 있다. </p><p>처음부터 이벤트 발생 시간을 파티션의 이름에 포함하도록 하여 시계열 테이블을 만들어보자. 예를 들어, 1월 1일에 발생한 이벤트라면 그 이벤트가 언제 서버에 도착했는지에 상관없이 &#x27;event_0101&#x27;이라는 파티션에 추가되어야 한다. </p><p>시계열 테이블을 구성하는 각 파티션에는 매일 조금씩 데이터가 추가 된다. 결과적으로 분산 스토리지에는 작은 파일들이 너무 많아지고, 점차 쿼리 성능이 악화된다. </p><p>따라서, <strong>이벤트 시간으로부터 시계열 테이블을 만든다면 작은 데이터를 효율적으로 추가할 수 있는 분산 DB를 사용하거나 너무 오래된 데이터는 버리는 아이디어가 필요하다.</strong></p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="데이터-마트를-이벤트-시간으로-정렬하기"></a>데이터 마트를 이벤트 시간으로 정렬하기<a class="hash-link" href="#데이터-마트를-이벤트-시간으로-정렬하기" title="Direct link to heading">#</a></h3><p>이에 더 좋은 아이디어를 생각해보면, 데이터 마트만 이벤트 시간에 따라 정렬하도록 만드는 것이다. 데이터 수집 단계에서는 이벤트 시간을 따지지 않고 프로세스 시간만 사용해서 데이터를 저장한다. 그리고 데이터 마트를 만드는 단계에서 이벤트 시간에 의한 정렬을 하도록 수행한다. 쿼리 엔진은 데이터 마트에 질의를 넣으면 되므로 파일이 조각나거나 최적이 아닌 데이터 마트를 유지하게 될 염려도 없다.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/wookiist/twl/edit/documentation/docs/Data Engineering/Introduction/de-intro-4.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_2_ui" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_13-_"><span class="theme-last-updated">Last updated on <b><time datetime="2021-10-06T10:16:37.000Z">10/6/2021</time></b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/Data Engineering/Introduction/de-intro-2"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">« CH2 - 빅데이터의 탐색</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/Data Engineering/Introduction/de-intro-5"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">CH5 - 빅데이터의 파이프라인 »</div></a></div></nav></div></div><div class="col col--3"><div class="tableOfContents_35-E thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#벌크-형과-스트리밍-형의-데이터-수집" class="table-of-contents__link">벌크 형과 스트리밍 형의 데이터 수집</a><ul><li><a href="#객체-스토리지와-데이터-수집" class="table-of-contents__link">객체 스토리지와 데이터 수집</a></li></ul></li><li><a href="#벌크-형의-데이터-전송" class="table-of-contents__link">벌크 형의 데이터 전송</a><ul><li><a href="#파일-사이즈-최적화" class="table-of-contents__link">파일 사이즈 최적화</a></li><li><a href="#데이터-전송의-워크플로" class="table-of-contents__link">데이터 전송의 워크플로</a></li></ul></li><li><a href="#스트리밍-형의-데이터-전송" class="table-of-contents__link">스트리밍 형의 데이터 전송</a></li><li><a href="#4-2-성능x신뢰성-메시지-딜리버리의-트레이드-오프" class="table-of-contents__link">4-2 성능x신뢰성 메시지 딜리버리의 트레이드 오프</a></li><li><a href="#메시지-브로커" class="table-of-contents__link">메시지 브로커</a><ul><li><a href="#push--pull" class="table-of-contents__link">PUSH &amp; PULL</a></li><li><a href="#메시지-라우팅" class="table-of-contents__link">메시지 라우팅</a></li></ul></li><li><a href="#메시지-딜리버리를-확실하게-수행하는-것은-어렵다" class="table-of-contents__link">메시지 딜리버리를 확실하게 수행하는 것은 어렵다</a><ul><li><a href="#at-most-once" class="table-of-contents__link">at most once</a></li><li><a href="#exactly-once" class="table-of-contents__link">exactly once</a></li><li><a href="#at-least-once" class="table-of-contents__link">at least once</a></li></ul></li><li><a href="#deduplication은-높은-비용의-작업" class="table-of-contents__link">Deduplication은 높은 비용의 작업</a><ul><li><a href="#오프셋을-이용한-중복-제거" class="table-of-contents__link">오프셋을 이용한 중복 제거</a></li><li><a href="#고유-id에-의한-중복-제거" class="table-of-contents__link">고유 ID에 의한 중복 제거</a></li><li><a href="#end-to-end-신뢰성" class="table-of-contents__link">End-to-End 신뢰성</a></li></ul></li><li><a href="#데이터-수집-파이프라인" class="table-of-contents__link">데이터 수집 파이프라인</a><ul><li><a href="#중복을-고려한-시스템-설계" class="table-of-contents__link">중복을 고려한 시스템 설계</a></li></ul></li><li><a href="#4-3-시계열-데이터의-최적화" class="table-of-contents__link">4-3 시계열 데이터의 최적화</a></li><li><a href="#프로세스-시간과-이벤트-시간" class="table-of-contents__link">프로세스 시간과 이벤트 시간</a></li><li><a href="#프로세스-시간에-의한-분할과-문제점" class="table-of-contents__link">프로세스 시간에 의한 분할과 문제점</a></li><li><a href="#시계열-인덱스" class="table-of-contents__link">시계열 인덱스</a></li><li><a href="#조건절-푸시다운" class="table-of-contents__link">조건절 푸시다운</a></li><li><a href="#이벤트-시간에-의한-분할" class="table-of-contents__link">이벤트 시간에 의한 분할</a><ul><li><a href="#데이터-마트를-이벤트-시간으로-정렬하기" class="table-of-contents__link">데이터 마트를 이벤트 시간으로 정렬하기</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2021 wookiist. Built by wookiist and with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.af4d6fe8.js"></script>
<script src="/assets/js/main.40a9dcb1.js"></script>
</body>
</html>